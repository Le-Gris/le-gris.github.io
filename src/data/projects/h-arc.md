---
title: 'A Comprehensive Behavioral Dataset for the Abstraction and Reasoning Corpus'
year: 2025
type: 'Research'
status: 'Published'
description: 'An empirical study estimating human performance on the Abstraction and Reasoning Corpus benchmark, providing insights into human cognitive abilities in visual reasoning tasks.'
tags:
  ['Machine Learning', 'Cognitive Science', 'Visual Reasoning', 'Benchmarking']
links:
  - name: 'Project Webpage'
    url: 'https://arc-visualizations.github.io'
  - name: 'Publication'
    url: 'https://www.nature.com/articles/s41597-025-05687-1'
  - name: 'GitHub Repository'
    url: 'https://github.com/Le-Gris/h-arc'
---

## Overview

This project presents H-ARC, a robust estimate of human performance on the Abstraction and Reasoning Corpus (ARC) benchmark. The ARC benchmark is designed to test artificial intelligence systems on tasks that require abstraction and reasoning capabilities similar to human cognition.

## Key Contributions

- Comprehensive evaluation of human performance on ARC tasks
- Analysis of the gap between human and machine performance
- Insights into the nature of visual reasoning and abstraction
- Open-source implementation and dataset

## Impact

This work provides crucial baseline data for understanding human cognitive abilities in visual reasoning tasks and helps establish realistic performance targets for AI systems attempting to match human-level reasoning capabilities.

## Technical Details

The study involved extensive human subject testing to establish reliable performance benchmarks, with careful attention to experimental design and statistical analysis to ensure robust results.
